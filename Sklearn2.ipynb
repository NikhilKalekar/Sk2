{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sklearn2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "z_xPBNQjoCwj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This example has been taken from SciKit documentation and has been\n",
        "# modifified to suit this assignment. You are free to make changes, but you\n",
        "# need to perform the task asked in the lab assignment\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings \n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import Binarizer\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Loading the Digits dataset\n",
        "#digits = datasets.load_digits()\n",
        "warnings.simplefilter(\"ignore\",DeprecationWarning)\n",
        "#warnings.simplefilter(\"ignore\",ConvergenceWarning)\n",
        "DF = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\", header = None)\n",
        "X = DF.iloc[:,1:14]\n",
        "y = DF.iloc[:,0]\n",
        "\n",
        "# Split the dataset in two equal parts into 80:20 ratio for train:test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "# This is a key step where you define the parameters and their possible values\n",
        "# that you would like to check.\n",
        "PrintClfier_array =['SVC','MLPClassifier','DecisionTreeClassifier','LogisticRegression',\n",
        "               'KNeighborsClassifier','BaggingClassifier','RandomForestClassifier','AdaBoostClassifier','GradientBoostingClassifier',\n",
        "               'XGBClassifier','GaussianNB'               \n",
        "              ]   \n",
        "\n",
        "tuned_parameters = [{'kernel': ['rbf', 'linear'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000], 'max_iter':[-1,600]},\n",
        "                    {'hidden_layer_sizes':[20,30],'activation':['relu','tanh'],'alpha':[0.0001,0.0002],'max_iter':[1000],'learning_rate':['constant','adaptive']},\n",
        "                    {'max_depth': [6,3,7], 'min_samples_split': [3,2,6],'max_features':[6,4,3],'min_impurity_decrease':[0.01,0.0]},\n",
        "                    {'penalty':['l1','l2'],'tol':[1e-3, 2e-3],'C':[1,5,10],'fit_intercept':[True,False]},\n",
        "                    {'n_neighbors':[2,6,10],'weights':['uniform','distance'],'algorithm':['kd_tree','brute'],'p':[1,2]}, \n",
        "                    {'n_estimators':[50,100],'max_samples':[10,20],'max_features':[6,10],'random_state':[1,3,5]},\n",
        "                    {'n_estimators':[30,50,100],'criterion':['gini','entropy'],'max_depth':[6,3],'max_features':[6,4]}, \n",
        "                    {'n_estimators':[100,150,200],'learning_rate':[1.0,1.5],'algorithm':['SAMME','SAMME.R'],'random_state':[1,3,5]},\n",
        "                    {'learning_rate':[0.1,0.245,0.4],'n_estimators':[100,150,200],'max_features':[6,3],'min_impurity_decrease':[0.1,0.01,0.2]},\n",
        "                    {'nthread':[-1,10,100],'learning_rate':[0.1,0.245,0.4], \"min_child_weight\": [3,5,9], \"booster\": ['gbtree', 'dart']}, \n",
        "                    {'priors':[None]}\n",
        "                   ]\n",
        "\n",
        "      \n",
        "Clfier_array =[SVC(),MLPClassifier(),DecisionTreeClassifier(),LogisticRegression(),\n",
        "               KNeighborsClassifier(),BaggingClassifier(),RandomForestClassifier(),AdaBoostClassifier(),GradientBoostingClassifier(),\n",
        "               XGBClassifier(),GaussianNB()               \n",
        "              ]      \n",
        "# We are going to limit ourselves to accuracy score, other options can be\n",
        "# seen here:\n",
        "# http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "# Some other values used are the predcision_macro, recall_macro\n",
        "scores = ['accuracy']\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nLZI6e3Cs2NX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def EstimatorClass(score,tuned_parameters,Clfier_array,PrintClfier_array):\n",
        "  print(\"# Tuning hyper-parameters for %s \\n\" % score)\n",
        "  print()\n",
        "  print(\"USING THE %s ESTIMATOR\"%PrintClfier_array)\n",
        "  print()\n",
        "\n",
        "  clf = GridSearchCV(Clfier_array, tuned_parameters, cv=5,\n",
        "                           scoring='%s' % score)\n",
        "  clf.fit(X_train, y_train)\n",
        "    \n",
        "  print(\"Best parameters set found on development set:\")\n",
        "  print()\n",
        "  print(clf.best_params_)\n",
        "  print()\n",
        "  print(\"Grid scores on development set:\")\n",
        "  print()\n",
        "  means = clf.cv_results_['mean_test_score']\n",
        "  stds = clf.cv_results_['std_test_score']\n",
        "  for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "      print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "  print()\n",
        "\n",
        "  print(\"Detailed classification report:\")\n",
        "  print()\n",
        "  print(\"The model is trained on the full development set.\")\n",
        "  print(\"The scores are computed on the full evaluation set.\")\n",
        "  print()\n",
        "  y_true, y_pred = y_test, clf.predict(X_test)\n",
        "  print(classification_report(y_true, y_pred))\n",
        "  print(\"Detailed confusion matrix:\")\n",
        "  print(confusion_matrix(y_true, y_pred))\n",
        "  print(\"Accuracy Score: \\n\")\n",
        "  print(accuracy_score(y_true, y_pred))\n",
        "  print(\"---------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "# Note the problem is too easy: the hyperparameter plateau is too flat and the\n",
        "# output model is the same for precision and recall with ties in quality.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f1ghVTbmrKmE",
        "colab_type": "code",
        "outputId": "6b4d9169-cd81-4b5b-9773-bd3c979b7634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1211
        }
      },
      "cell_type": "code",
      "source": [
        "#For SVC():\n",
        "i=0\n",
        "\n",
        "\n",
        "EstimatorClass(scores[0],tuned_parameters[i],Clfier_array[i],PrintClfier_array[i])\n",
        "i+=1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for accuracy \n",
            "\n",
            "\n",
            "USING THE SVC ESTIMATOR\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': -1}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.761 (+/-0.161) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': -1}\n",
            "0.761 (+/-0.161) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 600}\n",
            "0.937 (+/-0.080) for {'C': 1, 'gamma': 0.001, 'kernel': 'linear', 'max_iter': -1}\n",
            "0.937 (+/-0.080) for {'C': 1, 'gamma': 0.001, 'kernel': 'linear', 'max_iter': 600}\n",
            "0.387 (+/-0.013) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf', 'max_iter': -1}\n",
            "0.387 (+/-0.013) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf', 'max_iter': 600}\n",
            "0.937 (+/-0.080) for {'C': 1, 'gamma': 0.0001, 'kernel': 'linear', 'max_iter': -1}\n",
            "0.937 (+/-0.080) for {'C': 1, 'gamma': 0.0001, 'kernel': 'linear', 'max_iter': 600}\n",
            "0.979 (+/-0.034) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': -1}\n",
            "0.979 (+/-0.034) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 600}\n",
            "0.937 (+/-0.080) for {'C': 10, 'gamma': 0.001, 'kernel': 'linear', 'max_iter': -1}\n",
            "0.937 (+/-0.080) for {'C': 10, 'gamma': 0.001, 'kernel': 'linear', 'max_iter': 600}\n",
            "0.796 (+/-0.119) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf', 'max_iter': -1}\n",
            "0.796 (+/-0.119) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf', 'max_iter': 600}\n",
            "0.937 (+/-0.080) for {'C': 10, 'gamma': 0.0001, 'kernel': 'linear', 'max_iter': -1}\n",
            "0.937 (+/-0.080) for {'C': 10, 'gamma': 0.0001, 'kernel': 'linear', 'max_iter': 600}\n",
            "0.944 (+/-0.094) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': -1}\n",
            "0.944 (+/-0.094) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 600}\n",
            "0.937 (+/-0.080) for {'C': 100, 'gamma': 0.001, 'kernel': 'linear', 'max_iter': -1}\n",
            "0.937 (+/-0.080) for {'C': 100, 'gamma': 0.001, 'kernel': 'linear', 'max_iter': 600}\n",
            "0.972 (+/-0.052) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf', 'max_iter': -1}\n",
            "0.972 (+/-0.052) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf', 'max_iter': 600}\n",
            "0.937 (+/-0.080) for {'C': 100, 'gamma': 0.0001, 'kernel': 'linear', 'max_iter': -1}\n",
            "0.937 (+/-0.080) for {'C': 100, 'gamma': 0.0001, 'kernel': 'linear', 'max_iter': 600}\n",
            "0.937 (+/-0.080) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': -1}\n",
            "0.937 (+/-0.080) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 600}\n",
            "0.937 (+/-0.080) for {'C': 1000, 'gamma': 0.001, 'kernel': 'linear', 'max_iter': -1}\n",
            "0.937 (+/-0.080) for {'C': 1000, 'gamma': 0.001, 'kernel': 'linear', 'max_iter': 600}\n",
            "0.944 (+/-0.094) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf', 'max_iter': -1}\n",
            "0.944 (+/-0.094) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf', 'max_iter': 600}\n",
            "0.937 (+/-0.080) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'linear', 'max_iter': -1}\n",
            "0.937 (+/-0.080) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'linear', 'max_iter': 600}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       1.00      1.00      1.00        14\n",
            "          2       1.00      0.94      0.97        16\n",
            "          3       0.86      1.00      0.92         6\n",
            "\n",
            "avg / total       0.98      0.97      0.97        36\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[14  0  0]\n",
            " [ 0 15  1]\n",
            " [ 0  0  6]]\n",
            "Accuracy Score: \n",
            "\n",
            "0.9722222222222222\n",
            "---------------------------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "65JYmiW8ITdg",
        "colab_type": "code",
        "outputId": "e25e7912-d535-4fdb-e683-44957508d015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        }
      },
      "cell_type": "code",
      "source": [
        "#For NEURAL NETS:\n",
        "\n",
        "\n",
        "EstimatorClass(scores[0],tuned_parameters[i],Clfier_array[i],PrintClfier_array[i])\n",
        "i+=1\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for accuracy \n",
            "\n",
            "\n",
            "USING THE MLPClassifier ESTIMATOR\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 30, 'learning_rate': 'adaptive', 'max_iter': 1000}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.944 (+/-0.070) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 20, 'learning_rate': 'constant', 'max_iter': 1000}\n",
            "0.944 (+/-0.070) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 20, 'learning_rate': 'adaptive', 'max_iter': 1000}\n",
            "0.951 (+/-0.070) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 30, 'learning_rate': 'constant', 'max_iter': 1000}\n",
            "0.965 (+/-0.044) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 30, 'learning_rate': 'adaptive', 'max_iter': 1000}\n",
            "0.951 (+/-0.070) for {'activation': 'relu', 'alpha': 0.0002, 'hidden_layer_sizes': 20, 'learning_rate': 'constant', 'max_iter': 1000}\n",
            "0.944 (+/-0.094) for {'activation': 'relu', 'alpha': 0.0002, 'hidden_layer_sizes': 20, 'learning_rate': 'adaptive', 'max_iter': 1000}\n",
            "0.937 (+/-0.092) for {'activation': 'relu', 'alpha': 0.0002, 'hidden_layer_sizes': 30, 'learning_rate': 'constant', 'max_iter': 1000}\n",
            "0.951 (+/-0.070) for {'activation': 'relu', 'alpha': 0.0002, 'hidden_layer_sizes': 30, 'learning_rate': 'adaptive', 'max_iter': 1000}\n",
            "0.944 (+/-0.094) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 20, 'learning_rate': 'constant', 'max_iter': 1000}\n",
            "0.951 (+/-0.070) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 20, 'learning_rate': 'adaptive', 'max_iter': 1000}\n",
            "0.951 (+/-0.033) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 30, 'learning_rate': 'constant', 'max_iter': 1000}\n",
            "0.944 (+/-0.094) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 30, 'learning_rate': 'adaptive', 'max_iter': 1000}\n",
            "0.937 (+/-0.092) for {'activation': 'tanh', 'alpha': 0.0002, 'hidden_layer_sizes': 20, 'learning_rate': 'constant', 'max_iter': 1000}\n",
            "0.944 (+/-0.054) for {'activation': 'tanh', 'alpha': 0.0002, 'hidden_layer_sizes': 20, 'learning_rate': 'adaptive', 'max_iter': 1000}\n",
            "0.951 (+/-0.070) for {'activation': 'tanh', 'alpha': 0.0002, 'hidden_layer_sizes': 30, 'learning_rate': 'constant', 'max_iter': 1000}\n",
            "0.944 (+/-0.094) for {'activation': 'tanh', 'alpha': 0.0002, 'hidden_layer_sizes': 30, 'learning_rate': 'adaptive', 'max_iter': 1000}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       1.00      1.00      1.00        14\n",
            "          2       1.00      1.00      1.00        16\n",
            "          3       1.00      1.00      1.00         6\n",
            "\n",
            "avg / total       1.00      1.00      1.00        36\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[14  0  0]\n",
            " [ 0 16  0]\n",
            " [ 0  0  6]]\n",
            "Accuracy Score: \n",
            "\n",
            "1.0\n",
            "---------------------------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YmJTxydDIXRZ",
        "colab_type": "code",
        "outputId": "89d28c15-bc79-4e01-9753-408c375cd102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1615
        }
      },
      "cell_type": "code",
      "source": [
        "#For DT\n",
        "i=2\n",
        "EstimatorClass(scores[0],tuned_parameters[i],Clfier_array[i],PrintClfier_array[i])\n",
        "i+=1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for accuracy \n",
            "\n",
            "\n",
            "USING THE DecisionTreeClassifier ESTIMATOR\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'max_depth': 3, 'max_features': 6, 'min_impurity_decrease': 0.0, 'min_samples_split': 6}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.944 (+/-0.084) for {'max_depth': 6, 'max_features': 6, 'min_impurity_decrease': 0.01, 'min_samples_split': 3}\n",
            "0.923 (+/-0.094) for {'max_depth': 6, 'max_features': 6, 'min_impurity_decrease': 0.01, 'min_samples_split': 2}\n",
            "0.930 (+/-0.099) for {'max_depth': 6, 'max_features': 6, 'min_impurity_decrease': 0.01, 'min_samples_split': 6}\n",
            "0.923 (+/-0.103) for {'max_depth': 6, 'max_features': 6, 'min_impurity_decrease': 0.0, 'min_samples_split': 3}\n",
            "0.951 (+/-0.071) for {'max_depth': 6, 'max_features': 6, 'min_impurity_decrease': 0.0, 'min_samples_split': 2}\n",
            "0.923 (+/-0.082) for {'max_depth': 6, 'max_features': 6, 'min_impurity_decrease': 0.0, 'min_samples_split': 6}\n",
            "0.937 (+/-0.068) for {'max_depth': 6, 'max_features': 4, 'min_impurity_decrease': 0.01, 'min_samples_split': 3}\n",
            "0.915 (+/-0.132) for {'max_depth': 6, 'max_features': 4, 'min_impurity_decrease': 0.01, 'min_samples_split': 2}\n",
            "0.908 (+/-0.103) for {'max_depth': 6, 'max_features': 4, 'min_impurity_decrease': 0.01, 'min_samples_split': 6}\n",
            "0.930 (+/-0.090) for {'max_depth': 6, 'max_features': 4, 'min_impurity_decrease': 0.0, 'min_samples_split': 3}\n",
            "0.880 (+/-0.137) for {'max_depth': 6, 'max_features': 4, 'min_impurity_decrease': 0.0, 'min_samples_split': 2}\n",
            "0.915 (+/-0.132) for {'max_depth': 6, 'max_features': 4, 'min_impurity_decrease': 0.0, 'min_samples_split': 6}\n",
            "0.866 (+/-0.125) for {'max_depth': 6, 'max_features': 3, 'min_impurity_decrease': 0.01, 'min_samples_split': 3}\n",
            "0.894 (+/-0.099) for {'max_depth': 6, 'max_features': 3, 'min_impurity_decrease': 0.01, 'min_samples_split': 2}\n",
            "0.887 (+/-0.084) for {'max_depth': 6, 'max_features': 3, 'min_impurity_decrease': 0.01, 'min_samples_split': 6}\n",
            "0.845 (+/-0.159) for {'max_depth': 6, 'max_features': 3, 'min_impurity_decrease': 0.0, 'min_samples_split': 3}\n",
            "0.887 (+/-0.030) for {'max_depth': 6, 'max_features': 3, 'min_impurity_decrease': 0.0, 'min_samples_split': 2}\n",
            "0.930 (+/-0.063) for {'max_depth': 6, 'max_features': 3, 'min_impurity_decrease': 0.0, 'min_samples_split': 6}\n",
            "0.915 (+/-0.113) for {'max_depth': 3, 'max_features': 6, 'min_impurity_decrease': 0.01, 'min_samples_split': 3}\n",
            "0.887 (+/-0.067) for {'max_depth': 3, 'max_features': 6, 'min_impurity_decrease': 0.01, 'min_samples_split': 2}\n",
            "0.880 (+/-0.135) for {'max_depth': 3, 'max_features': 6, 'min_impurity_decrease': 0.01, 'min_samples_split': 6}\n",
            "0.915 (+/-0.069) for {'max_depth': 3, 'max_features': 6, 'min_impurity_decrease': 0.0, 'min_samples_split': 3}\n",
            "0.951 (+/-0.106) for {'max_depth': 3, 'max_features': 6, 'min_impurity_decrease': 0.0, 'min_samples_split': 2}\n",
            "0.958 (+/-0.111) for {'max_depth': 3, 'max_features': 6, 'min_impurity_decrease': 0.0, 'min_samples_split': 6}\n",
            "0.887 (+/-0.052) for {'max_depth': 3, 'max_features': 4, 'min_impurity_decrease': 0.01, 'min_samples_split': 3}\n",
            "0.852 (+/-0.051) for {'max_depth': 3, 'max_features': 4, 'min_impurity_decrease': 0.01, 'min_samples_split': 2}\n",
            "0.915 (+/-0.074) for {'max_depth': 3, 'max_features': 4, 'min_impurity_decrease': 0.01, 'min_samples_split': 6}\n",
            "0.845 (+/-0.106) for {'max_depth': 3, 'max_features': 4, 'min_impurity_decrease': 0.0, 'min_samples_split': 3}\n",
            "0.923 (+/-0.104) for {'max_depth': 3, 'max_features': 4, 'min_impurity_decrease': 0.0, 'min_samples_split': 2}\n",
            "0.845 (+/-0.129) for {'max_depth': 3, 'max_features': 4, 'min_impurity_decrease': 0.0, 'min_samples_split': 6}\n",
            "0.810 (+/-0.115) for {'max_depth': 3, 'max_features': 3, 'min_impurity_decrease': 0.01, 'min_samples_split': 3}\n",
            "0.852 (+/-0.214) for {'max_depth': 3, 'max_features': 3, 'min_impurity_decrease': 0.01, 'min_samples_split': 2}\n",
            "0.866 (+/-0.091) for {'max_depth': 3, 'max_features': 3, 'min_impurity_decrease': 0.01, 'min_samples_split': 6}\n",
            "0.887 (+/-0.199) for {'max_depth': 3, 'max_features': 3, 'min_impurity_decrease': 0.0, 'min_samples_split': 3}\n",
            "0.901 (+/-0.081) for {'max_depth': 3, 'max_features': 3, 'min_impurity_decrease': 0.0, 'min_samples_split': 2}\n",
            "0.894 (+/-0.122) for {'max_depth': 3, 'max_features': 3, 'min_impurity_decrease': 0.0, 'min_samples_split': 6}\n",
            "0.944 (+/-0.084) for {'max_depth': 7, 'max_features': 6, 'min_impurity_decrease': 0.01, 'min_samples_split': 3}\n",
            "0.894 (+/-0.089) for {'max_depth': 7, 'max_features': 6, 'min_impurity_decrease': 0.01, 'min_samples_split': 2}\n",
            "0.908 (+/-0.084) for {'max_depth': 7, 'max_features': 6, 'min_impurity_decrease': 0.01, 'min_samples_split': 6}\n",
            "0.930 (+/-0.063) for {'max_depth': 7, 'max_features': 6, 'min_impurity_decrease': 0.0, 'min_samples_split': 3}\n",
            "0.923 (+/-0.081) for {'max_depth': 7, 'max_features': 6, 'min_impurity_decrease': 0.0, 'min_samples_split': 2}\n",
            "0.908 (+/-0.071) for {'max_depth': 7, 'max_features': 6, 'min_impurity_decrease': 0.0, 'min_samples_split': 6}\n",
            "0.951 (+/-0.094) for {'max_depth': 7, 'max_features': 4, 'min_impurity_decrease': 0.01, 'min_samples_split': 3}\n",
            "0.937 (+/-0.092) for {'max_depth': 7, 'max_features': 4, 'min_impurity_decrease': 0.01, 'min_samples_split': 2}\n",
            "0.930 (+/-0.043) for {'max_depth': 7, 'max_features': 4, 'min_impurity_decrease': 0.01, 'min_samples_split': 6}\n",
            "0.859 (+/-0.151) for {'max_depth': 7, 'max_features': 4, 'min_impurity_decrease': 0.0, 'min_samples_split': 3}\n",
            "0.930 (+/-0.076) for {'max_depth': 7, 'max_features': 4, 'min_impurity_decrease': 0.0, 'min_samples_split': 2}\n",
            "0.894 (+/-0.130) for {'max_depth': 7, 'max_features': 4, 'min_impurity_decrease': 0.0, 'min_samples_split': 6}\n",
            "0.894 (+/-0.115) for {'max_depth': 7, 'max_features': 3, 'min_impurity_decrease': 0.01, 'min_samples_split': 3}\n",
            "0.901 (+/-0.112) for {'max_depth': 7, 'max_features': 3, 'min_impurity_decrease': 0.01, 'min_samples_split': 2}\n",
            "0.887 (+/-0.052) for {'max_depth': 7, 'max_features': 3, 'min_impurity_decrease': 0.01, 'min_samples_split': 6}\n",
            "0.901 (+/-0.092) for {'max_depth': 7, 'max_features': 3, 'min_impurity_decrease': 0.0, 'min_samples_split': 3}\n",
            "0.901 (+/-0.111) for {'max_depth': 7, 'max_features': 3, 'min_impurity_decrease': 0.0, 'min_samples_split': 2}\n",
            "0.908 (+/-0.073) for {'max_depth': 7, 'max_features': 3, 'min_impurity_decrease': 0.0, 'min_samples_split': 6}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.88      1.00      0.93        14\n",
            "          2       1.00      0.81      0.90        16\n",
            "          3       0.86      1.00      0.92         6\n",
            "\n",
            "avg / total       0.93      0.92      0.92        36\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[14  0  0]\n",
            " [ 2 13  1]\n",
            " [ 0  0  6]]\n",
            "Accuracy Score: \n",
            "\n",
            "0.9166666666666666\n",
            "---------------------------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3l5SQ4z7IdeR",
        "colab_type": "code",
        "outputId": "46fb8b3b-5877-4d66-e1b3-94a97ed667ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1064
        }
      },
      "cell_type": "code",
      "source": [
        "#For Logistic Regression \n",
        "\n",
        "i=3\n",
        "EstimatorClass(scores[0],tuned_parameters[i],Clfier_array[i],PrintClfier_array[i])\n",
        "i+=1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for accuracy \n",
            "\n",
            "\n",
            "USING THE LogisticRegression ESTIMATOR\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'C': 1, 'fit_intercept': True, 'penalty': 'l1', 'tol': 0.001}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.972 (+/-0.028) for {'C': 1, 'fit_intercept': True, 'penalty': 'l1', 'tol': 0.001}\n",
            "0.972 (+/-0.028) for {'C': 1, 'fit_intercept': True, 'penalty': 'l1', 'tol': 0.002}\n",
            "0.951 (+/-0.070) for {'C': 1, 'fit_intercept': True, 'penalty': 'l2', 'tol': 0.001}\n",
            "0.951 (+/-0.070) for {'C': 1, 'fit_intercept': True, 'penalty': 'l2', 'tol': 0.002}\n",
            "0.972 (+/-0.052) for {'C': 1, 'fit_intercept': False, 'penalty': 'l1', 'tol': 0.001}\n",
            "0.972 (+/-0.052) for {'C': 1, 'fit_intercept': False, 'penalty': 'l1', 'tol': 0.002}\n",
            "0.965 (+/-0.062) for {'C': 1, 'fit_intercept': False, 'penalty': 'l2', 'tol': 0.001}\n",
            "0.965 (+/-0.062) for {'C': 1, 'fit_intercept': False, 'penalty': 'l2', 'tol': 0.002}\n",
            "0.951 (+/-0.070) for {'C': 5, 'fit_intercept': True, 'penalty': 'l1', 'tol': 0.001}\n",
            "0.951 (+/-0.070) for {'C': 5, 'fit_intercept': True, 'penalty': 'l1', 'tol': 0.002}\n",
            "0.951 (+/-0.070) for {'C': 5, 'fit_intercept': True, 'penalty': 'l2', 'tol': 0.001}\n",
            "0.951 (+/-0.070) for {'C': 5, 'fit_intercept': True, 'penalty': 'l2', 'tol': 0.002}\n",
            "0.972 (+/-0.052) for {'C': 5, 'fit_intercept': False, 'penalty': 'l1', 'tol': 0.001}\n",
            "0.972 (+/-0.052) for {'C': 5, 'fit_intercept': False, 'penalty': 'l1', 'tol': 0.002}\n",
            "0.965 (+/-0.062) for {'C': 5, 'fit_intercept': False, 'penalty': 'l2', 'tol': 0.001}\n",
            "0.965 (+/-0.062) for {'C': 5, 'fit_intercept': False, 'penalty': 'l2', 'tol': 0.002}\n",
            "0.951 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'penalty': 'l1', 'tol': 0.001}\n",
            "0.951 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'penalty': 'l1', 'tol': 0.002}\n",
            "0.951 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'penalty': 'l2', 'tol': 0.001}\n",
            "0.951 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'penalty': 'l2', 'tol': 0.002}\n",
            "0.965 (+/-0.076) for {'C': 10, 'fit_intercept': False, 'penalty': 'l1', 'tol': 0.001}\n",
            "0.965 (+/-0.076) for {'C': 10, 'fit_intercept': False, 'penalty': 'l1', 'tol': 0.002}\n",
            "0.958 (+/-0.081) for {'C': 10, 'fit_intercept': False, 'penalty': 'l2', 'tol': 0.001}\n",
            "0.958 (+/-0.081) for {'C': 10, 'fit_intercept': False, 'penalty': 'l2', 'tol': 0.002}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       1.00      1.00      1.00        14\n",
            "          2       1.00      1.00      1.00        16\n",
            "          3       1.00      1.00      1.00         6\n",
            "\n",
            "avg / total       1.00      1.00      1.00        36\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[14  0  0]\n",
            " [ 0 16  0]\n",
            " [ 0  0  6]]\n",
            "Accuracy Score: \n",
            "\n",
            "1.0\n",
            "---------------------------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "14HxV98IuoBd",
        "colab_type": "code",
        "outputId": "4891ee70-3413-41b6-d449-f1b906a624d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1064
        }
      },
      "cell_type": "code",
      "source": [
        "#For KNN\n",
        "\n",
        "i=4\n",
        "EstimatorClass(scores[0],tuned_parameters[i],Clfier_array[i],PrintClfier_array[i])\n",
        "i+=1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for accuracy \n",
            "\n",
            "\n",
            "USING THE KNeighborsClassifier ESTIMATOR\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'algorithm': 'kd_tree', 'n_neighbors': 6, 'p': 2, 'weights': 'uniform'}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.965 (+/-0.076) for {'algorithm': 'kd_tree', 'n_neighbors': 2, 'p': 1, 'weights': 'uniform'}\n",
            "0.965 (+/-0.076) for {'algorithm': 'kd_tree', 'n_neighbors': 2, 'p': 1, 'weights': 'distance'}\n",
            "0.944 (+/-0.094) for {'algorithm': 'kd_tree', 'n_neighbors': 2, 'p': 2, 'weights': 'uniform'}\n",
            "0.958 (+/-0.081) for {'algorithm': 'kd_tree', 'n_neighbors': 2, 'p': 2, 'weights': 'distance'}\n",
            "0.965 (+/-0.044) for {'algorithm': 'kd_tree', 'n_neighbors': 6, 'p': 1, 'weights': 'uniform'}\n",
            "0.965 (+/-0.044) for {'algorithm': 'kd_tree', 'n_neighbors': 6, 'p': 1, 'weights': 'distance'}\n",
            "0.972 (+/-0.052) for {'algorithm': 'kd_tree', 'n_neighbors': 6, 'p': 2, 'weights': 'uniform'}\n",
            "0.958 (+/-0.081) for {'algorithm': 'kd_tree', 'n_neighbors': 6, 'p': 2, 'weights': 'distance'}\n",
            "0.965 (+/-0.063) for {'algorithm': 'kd_tree', 'n_neighbors': 10, 'p': 1, 'weights': 'uniform'}\n",
            "0.965 (+/-0.063) for {'algorithm': 'kd_tree', 'n_neighbors': 10, 'p': 1, 'weights': 'distance'}\n",
            "0.958 (+/-0.068) for {'algorithm': 'kd_tree', 'n_neighbors': 10, 'p': 2, 'weights': 'uniform'}\n",
            "0.958 (+/-0.051) for {'algorithm': 'kd_tree', 'n_neighbors': 10, 'p': 2, 'weights': 'distance'}\n",
            "0.965 (+/-0.076) for {'algorithm': 'brute', 'n_neighbors': 2, 'p': 1, 'weights': 'uniform'}\n",
            "0.965 (+/-0.076) for {'algorithm': 'brute', 'n_neighbors': 2, 'p': 1, 'weights': 'distance'}\n",
            "0.944 (+/-0.094) for {'algorithm': 'brute', 'n_neighbors': 2, 'p': 2, 'weights': 'uniform'}\n",
            "0.958 (+/-0.081) for {'algorithm': 'brute', 'n_neighbors': 2, 'p': 2, 'weights': 'distance'}\n",
            "0.965 (+/-0.044) for {'algorithm': 'brute', 'n_neighbors': 6, 'p': 1, 'weights': 'uniform'}\n",
            "0.965 (+/-0.044) for {'algorithm': 'brute', 'n_neighbors': 6, 'p': 1, 'weights': 'distance'}\n",
            "0.972 (+/-0.052) for {'algorithm': 'brute', 'n_neighbors': 6, 'p': 2, 'weights': 'uniform'}\n",
            "0.958 (+/-0.081) for {'algorithm': 'brute', 'n_neighbors': 6, 'p': 2, 'weights': 'distance'}\n",
            "0.965 (+/-0.063) for {'algorithm': 'brute', 'n_neighbors': 10, 'p': 1, 'weights': 'uniform'}\n",
            "0.965 (+/-0.063) for {'algorithm': 'brute', 'n_neighbors': 10, 'p': 1, 'weights': 'distance'}\n",
            "0.958 (+/-0.068) for {'algorithm': 'brute', 'n_neighbors': 10, 'p': 2, 'weights': 'uniform'}\n",
            "0.958 (+/-0.051) for {'algorithm': 'brute', 'n_neighbors': 10, 'p': 2, 'weights': 'distance'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       1.00      1.00      1.00        14\n",
            "          2       1.00      1.00      1.00        16\n",
            "          3       1.00      1.00      1.00         6\n",
            "\n",
            "avg / total       1.00      1.00      1.00        36\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[14  0  0]\n",
            " [ 0 16  0]\n",
            " [ 0  0  6]]\n",
            "Accuracy Score: \n",
            "\n",
            "1.0\n",
            "---------------------------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zOL56ngauv_W",
        "colab_type": "code",
        "outputId": "a23fcb61-a341-47ca-cd0f-e18e05e290bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1064
        }
      },
      "cell_type": "code",
      "source": [
        "#For Bagging\n",
        "\n",
        "i=5\n",
        "EstimatorClass(scores[0],tuned_parameters[i],Clfier_array[i],PrintClfier_array[i])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for accuracy \n",
            "\n",
            "\n",
            "USING THE BaggingClassifier ESTIMATOR\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'max_features': 6, 'max_samples': 10, 'n_estimators': 100, 'random_state': 3}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.972 (+/-0.053) for {'max_features': 6, 'max_samples': 10, 'n_estimators': 50, 'random_state': 1}\n",
            "0.972 (+/-0.028) for {'max_features': 6, 'max_samples': 10, 'n_estimators': 50, 'random_state': 3}\n",
            "0.965 (+/-0.044) for {'max_features': 6, 'max_samples': 10, 'n_estimators': 50, 'random_state': 5}\n",
            "0.979 (+/-0.034) for {'max_features': 6, 'max_samples': 10, 'n_estimators': 100, 'random_state': 1}\n",
            "0.986 (+/-0.034) for {'max_features': 6, 'max_samples': 10, 'n_estimators': 100, 'random_state': 3}\n",
            "0.965 (+/-0.044) for {'max_features': 6, 'max_samples': 10, 'n_estimators': 100, 'random_state': 5}\n",
            "0.972 (+/-0.068) for {'max_features': 6, 'max_samples': 20, 'n_estimators': 50, 'random_state': 1}\n",
            "0.972 (+/-0.052) for {'max_features': 6, 'max_samples': 20, 'n_estimators': 50, 'random_state': 3}\n",
            "0.965 (+/-0.063) for {'max_features': 6, 'max_samples': 20, 'n_estimators': 50, 'random_state': 5}\n",
            "0.972 (+/-0.068) for {'max_features': 6, 'max_samples': 20, 'n_estimators': 100, 'random_state': 1}\n",
            "0.986 (+/-0.034) for {'max_features': 6, 'max_samples': 20, 'n_estimators': 100, 'random_state': 3}\n",
            "0.979 (+/-0.034) for {'max_features': 6, 'max_samples': 20, 'n_estimators': 100, 'random_state': 5}\n",
            "0.965 (+/-0.045) for {'max_features': 10, 'max_samples': 10, 'n_estimators': 50, 'random_state': 1}\n",
            "0.979 (+/-0.034) for {'max_features': 10, 'max_samples': 10, 'n_estimators': 50, 'random_state': 3}\n",
            "0.986 (+/-0.034) for {'max_features': 10, 'max_samples': 10, 'n_estimators': 50, 'random_state': 5}\n",
            "0.958 (+/-0.052) for {'max_features': 10, 'max_samples': 10, 'n_estimators': 100, 'random_state': 1}\n",
            "0.979 (+/-0.055) for {'max_features': 10, 'max_samples': 10, 'n_estimators': 100, 'random_state': 3}\n",
            "0.986 (+/-0.034) for {'max_features': 10, 'max_samples': 10, 'n_estimators': 100, 'random_state': 5}\n",
            "0.972 (+/-0.052) for {'max_features': 10, 'max_samples': 20, 'n_estimators': 50, 'random_state': 1}\n",
            "0.972 (+/-0.028) for {'max_features': 10, 'max_samples': 20, 'n_estimators': 50, 'random_state': 3}\n",
            "0.986 (+/-0.034) for {'max_features': 10, 'max_samples': 20, 'n_estimators': 50, 'random_state': 5}\n",
            "0.965 (+/-0.044) for {'max_features': 10, 'max_samples': 20, 'n_estimators': 100, 'random_state': 1}\n",
            "0.965 (+/-0.044) for {'max_features': 10, 'max_samples': 20, 'n_estimators': 100, 'random_state': 3}\n",
            "0.986 (+/-0.034) for {'max_features': 10, 'max_samples': 20, 'n_estimators': 100, 'random_state': 5}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.93      1.00      0.97        14\n",
            "          2       1.00      0.94      0.97        16\n",
            "          3       1.00      1.00      1.00         6\n",
            "\n",
            "avg / total       0.97      0.97      0.97        36\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[14  0  0]\n",
            " [ 1 15  0]\n",
            " [ 0  0  6]]\n",
            "Accuracy Score: \n",
            "\n",
            "0.9722222222222222\n",
            "---------------------------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Az1n-ordu4Sg",
        "colab_type": "code",
        "outputId": "caa45aa1-8d51-486c-fd21-c8fd2e437428",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1064
        }
      },
      "cell_type": "code",
      "source": [
        "#For RandomForest \n",
        "\n",
        "i=6\n",
        "EstimatorClass(scores[0],tuned_parameters[i],Clfier_array[i],PrintClfier_array[i])\n",
        "i+=1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for accuracy \n",
            "\n",
            "\n",
            "USING THE RandomForestClassifier ESTIMATOR\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'criterion': 'gini', 'max_depth': 6, 'max_features': 4, 'n_estimators': 100}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.972 (+/-0.052) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 6, 'n_estimators': 30}\n",
            "0.979 (+/-0.034) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 6, 'n_estimators': 50}\n",
            "0.979 (+/-0.034) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 6, 'n_estimators': 100}\n",
            "0.972 (+/-0.053) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 4, 'n_estimators': 30}\n",
            "0.972 (+/-0.052) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 4, 'n_estimators': 50}\n",
            "0.986 (+/-0.034) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 4, 'n_estimators': 100}\n",
            "0.979 (+/-0.034) for {'criterion': 'gini', 'max_depth': 3, 'max_features': 6, 'n_estimators': 30}\n",
            "0.986 (+/-0.034) for {'criterion': 'gini', 'max_depth': 3, 'max_features': 6, 'n_estimators': 50}\n",
            "0.979 (+/-0.034) for {'criterion': 'gini', 'max_depth': 3, 'max_features': 6, 'n_estimators': 100}\n",
            "0.979 (+/-0.034) for {'criterion': 'gini', 'max_depth': 3, 'max_features': 4, 'n_estimators': 30}\n",
            "0.979 (+/-0.055) for {'criterion': 'gini', 'max_depth': 3, 'max_features': 4, 'n_estimators': 50}\n",
            "0.986 (+/-0.034) for {'criterion': 'gini', 'max_depth': 3, 'max_features': 4, 'n_estimators': 100}\n",
            "0.972 (+/-0.052) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 6, 'n_estimators': 30}\n",
            "0.979 (+/-0.055) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 6, 'n_estimators': 50}\n",
            "0.972 (+/-0.052) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 6, 'n_estimators': 100}\n",
            "0.986 (+/-0.034) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 4, 'n_estimators': 30}\n",
            "0.979 (+/-0.055) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 4, 'n_estimators': 50}\n",
            "0.986 (+/-0.034) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 4, 'n_estimators': 100}\n",
            "0.979 (+/-0.034) for {'criterion': 'entropy', 'max_depth': 3, 'max_features': 6, 'n_estimators': 30}\n",
            "0.979 (+/-0.055) for {'criterion': 'entropy', 'max_depth': 3, 'max_features': 6, 'n_estimators': 50}\n",
            "0.979 (+/-0.055) for {'criterion': 'entropy', 'max_depth': 3, 'max_features': 6, 'n_estimators': 100}\n",
            "0.965 (+/-0.063) for {'criterion': 'entropy', 'max_depth': 3, 'max_features': 4, 'n_estimators': 30}\n",
            "0.979 (+/-0.034) for {'criterion': 'entropy', 'max_depth': 3, 'max_features': 4, 'n_estimators': 50}\n",
            "0.979 (+/-0.055) for {'criterion': 'entropy', 'max_depth': 3, 'max_features': 4, 'n_estimators': 100}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       1.00      1.00      1.00        14\n",
            "          2       1.00      0.94      0.97        16\n",
            "          3       0.86      1.00      0.92         6\n",
            "\n",
            "avg / total       0.98      0.97      0.97        36\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[14  0  0]\n",
            " [ 0 15  1]\n",
            " [ 0  0  6]]\n",
            "Accuracy Score: \n",
            "\n",
            "0.9722222222222222\n",
            "---------------------------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PFKcWo7Yu4M6",
        "colab_type": "code",
        "outputId": "4155dbb4-fad1-40fa-aae4-e90745db7d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1284
        }
      },
      "cell_type": "code",
      "source": [
        "#For AdaBoost\n",
        "\n",
        "i=7\n",
        "EstimatorClass(scores[0],tuned_parameters[i],Clfier_array[i],PrintClfier_array[i])\n",
        "i+=1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for accuracy \n",
            "\n",
            "\n",
            "USING THE AdaBoostClassifier ESTIMATOR\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'algorithm': 'SAMME', 'learning_rate': 1.0, 'n_estimators': 100, 'random_state': 1}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.979 (+/-0.057) for {'algorithm': 'SAMME', 'learning_rate': 1.0, 'n_estimators': 100, 'random_state': 1}\n",
            "0.979 (+/-0.057) for {'algorithm': 'SAMME', 'learning_rate': 1.0, 'n_estimators': 100, 'random_state': 3}\n",
            "0.979 (+/-0.057) for {'algorithm': 'SAMME', 'learning_rate': 1.0, 'n_estimators': 100, 'random_state': 5}\n",
            "0.972 (+/-0.053) for {'algorithm': 'SAMME', 'learning_rate': 1.0, 'n_estimators': 150, 'random_state': 1}\n",
            "0.972 (+/-0.053) for {'algorithm': 'SAMME', 'learning_rate': 1.0, 'n_estimators': 150, 'random_state': 3}\n",
            "0.972 (+/-0.053) for {'algorithm': 'SAMME', 'learning_rate': 1.0, 'n_estimators': 150, 'random_state': 5}\n",
            "0.972 (+/-0.053) for {'algorithm': 'SAMME', 'learning_rate': 1.0, 'n_estimators': 200, 'random_state': 1}\n",
            "0.972 (+/-0.053) for {'algorithm': 'SAMME', 'learning_rate': 1.0, 'n_estimators': 200, 'random_state': 3}\n",
            "0.972 (+/-0.053) for {'algorithm': 'SAMME', 'learning_rate': 1.0, 'n_estimators': 200, 'random_state': 5}\n",
            "0.944 (+/-0.086) for {'algorithm': 'SAMME', 'learning_rate': 1.5, 'n_estimators': 100, 'random_state': 1}\n",
            "0.944 (+/-0.086) for {'algorithm': 'SAMME', 'learning_rate': 1.5, 'n_estimators': 100, 'random_state': 3}\n",
            "0.944 (+/-0.086) for {'algorithm': 'SAMME', 'learning_rate': 1.5, 'n_estimators': 100, 'random_state': 5}\n",
            "0.951 (+/-0.097) for {'algorithm': 'SAMME', 'learning_rate': 1.5, 'n_estimators': 150, 'random_state': 1}\n",
            "0.951 (+/-0.097) for {'algorithm': 'SAMME', 'learning_rate': 1.5, 'n_estimators': 150, 'random_state': 3}\n",
            "0.951 (+/-0.097) for {'algorithm': 'SAMME', 'learning_rate': 1.5, 'n_estimators': 150, 'random_state': 5}\n",
            "0.951 (+/-0.097) for {'algorithm': 'SAMME', 'learning_rate': 1.5, 'n_estimators': 200, 'random_state': 1}\n",
            "0.951 (+/-0.097) for {'algorithm': 'SAMME', 'learning_rate': 1.5, 'n_estimators': 200, 'random_state': 3}\n",
            "0.951 (+/-0.097) for {'algorithm': 'SAMME', 'learning_rate': 1.5, 'n_estimators': 200, 'random_state': 5}\n",
            "0.908 (+/-0.086) for {'algorithm': 'SAMME.R', 'learning_rate': 1.0, 'n_estimators': 100, 'random_state': 1}\n",
            "0.901 (+/-0.071) for {'algorithm': 'SAMME.R', 'learning_rate': 1.0, 'n_estimators': 100, 'random_state': 3}\n",
            "0.901 (+/-0.071) for {'algorithm': 'SAMME.R', 'learning_rate': 1.0, 'n_estimators': 100, 'random_state': 5}\n",
            "0.908 (+/-0.086) for {'algorithm': 'SAMME.R', 'learning_rate': 1.0, 'n_estimators': 150, 'random_state': 1}\n",
            "0.901 (+/-0.071) for {'algorithm': 'SAMME.R', 'learning_rate': 1.0, 'n_estimators': 150, 'random_state': 3}\n",
            "0.901 (+/-0.071) for {'algorithm': 'SAMME.R', 'learning_rate': 1.0, 'n_estimators': 150, 'random_state': 5}\n",
            "0.908 (+/-0.086) for {'algorithm': 'SAMME.R', 'learning_rate': 1.0, 'n_estimators': 200, 'random_state': 1}\n",
            "0.901 (+/-0.071) for {'algorithm': 'SAMME.R', 'learning_rate': 1.0, 'n_estimators': 200, 'random_state': 3}\n",
            "0.901 (+/-0.071) for {'algorithm': 'SAMME.R', 'learning_rate': 1.0, 'n_estimators': 200, 'random_state': 5}\n",
            "0.831 (+/-0.287) for {'algorithm': 'SAMME.R', 'learning_rate': 1.5, 'n_estimators': 100, 'random_state': 1}\n",
            "0.831 (+/-0.284) for {'algorithm': 'SAMME.R', 'learning_rate': 1.5, 'n_estimators': 100, 'random_state': 3}\n",
            "0.831 (+/-0.287) for {'algorithm': 'SAMME.R', 'learning_rate': 1.5, 'n_estimators': 100, 'random_state': 5}\n",
            "0.831 (+/-0.287) for {'algorithm': 'SAMME.R', 'learning_rate': 1.5, 'n_estimators': 150, 'random_state': 1}\n",
            "0.838 (+/-0.298) for {'algorithm': 'SAMME.R', 'learning_rate': 1.5, 'n_estimators': 150, 'random_state': 3}\n",
            "0.831 (+/-0.287) for {'algorithm': 'SAMME.R', 'learning_rate': 1.5, 'n_estimators': 150, 'random_state': 5}\n",
            "0.831 (+/-0.287) for {'algorithm': 'SAMME.R', 'learning_rate': 1.5, 'n_estimators': 200, 'random_state': 1}\n",
            "0.838 (+/-0.298) for {'algorithm': 'SAMME.R', 'learning_rate': 1.5, 'n_estimators': 200, 'random_state': 3}\n",
            "0.831 (+/-0.287) for {'algorithm': 'SAMME.R', 'learning_rate': 1.5, 'n_estimators': 200, 'random_state': 5}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.82      1.00      0.90        14\n",
            "          2       1.00      0.75      0.86        16\n",
            "          3       0.86      1.00      0.92         6\n",
            "\n",
            "avg / total       0.91      0.89      0.89        36\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[14  0  0]\n",
            " [ 3 12  1]\n",
            " [ 0  0  6]]\n",
            "Accuracy Score: \n",
            "\n",
            "0.8888888888888888\n",
            "---------------------------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zDDjMKm0u4Fc",
        "colab_type": "code",
        "outputId": "24eacce5-f676-46e2-a090-b232015d3e11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1615
        }
      },
      "cell_type": "code",
      "source": [
        "#For GradBoost\n",
        "\n",
        "i=8\n",
        "EstimatorClass(scores[0],tuned_parameters[i],Clfier_array[i],PrintClfier_array[i])\n",
        "i+=1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for accuracy \n",
            "\n",
            "\n",
            "USING THE GradientBoostingClassifier ESTIMATOR\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'learning_rate': 0.1, 'max_features': 6, 'min_impurity_decrease': 0.01, 'n_estimators': 200}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.972 (+/-0.028) for {'learning_rate': 0.1, 'max_features': 6, 'min_impurity_decrease': 0.1, 'n_estimators': 100}\n",
            "0.986 (+/-0.034) for {'learning_rate': 0.1, 'max_features': 6, 'min_impurity_decrease': 0.1, 'n_estimators': 150}\n",
            "0.979 (+/-0.034) for {'learning_rate': 0.1, 'max_features': 6, 'min_impurity_decrease': 0.1, 'n_estimators': 200}\n",
            "0.986 (+/-0.034) for {'learning_rate': 0.1, 'max_features': 6, 'min_impurity_decrease': 0.01, 'n_estimators': 100}\n",
            "0.986 (+/-0.034) for {'learning_rate': 0.1, 'max_features': 6, 'min_impurity_decrease': 0.01, 'n_estimators': 150}\n",
            "0.993 (+/-0.028) for {'learning_rate': 0.1, 'max_features': 6, 'min_impurity_decrease': 0.01, 'n_estimators': 200}\n",
            "0.979 (+/-0.034) for {'learning_rate': 0.1, 'max_features': 6, 'min_impurity_decrease': 0.2, 'n_estimators': 100}\n",
            "0.979 (+/-0.034) for {'learning_rate': 0.1, 'max_features': 6, 'min_impurity_decrease': 0.2, 'n_estimators': 150}\n",
            "0.986 (+/-0.034) for {'learning_rate': 0.1, 'max_features': 6, 'min_impurity_decrease': 0.2, 'n_estimators': 200}\n",
            "0.993 (+/-0.028) for {'learning_rate': 0.1, 'max_features': 3, 'min_impurity_decrease': 0.1, 'n_estimators': 100}\n",
            "0.986 (+/-0.034) for {'learning_rate': 0.1, 'max_features': 3, 'min_impurity_decrease': 0.1, 'n_estimators': 150}\n",
            "0.979 (+/-0.055) for {'learning_rate': 0.1, 'max_features': 3, 'min_impurity_decrease': 0.1, 'n_estimators': 200}\n",
            "0.986 (+/-0.034) for {'learning_rate': 0.1, 'max_features': 3, 'min_impurity_decrease': 0.01, 'n_estimators': 100}\n",
            "0.979 (+/-0.034) for {'learning_rate': 0.1, 'max_features': 3, 'min_impurity_decrease': 0.01, 'n_estimators': 150}\n",
            "0.979 (+/-0.055) for {'learning_rate': 0.1, 'max_features': 3, 'min_impurity_decrease': 0.01, 'n_estimators': 200}\n",
            "0.986 (+/-0.034) for {'learning_rate': 0.1, 'max_features': 3, 'min_impurity_decrease': 0.2, 'n_estimators': 100}\n",
            "0.972 (+/-0.052) for {'learning_rate': 0.1, 'max_features': 3, 'min_impurity_decrease': 0.2, 'n_estimators': 150}\n",
            "0.986 (+/-0.034) for {'learning_rate': 0.1, 'max_features': 3, 'min_impurity_decrease': 0.2, 'n_estimators': 200}\n",
            "0.972 (+/-0.053) for {'learning_rate': 0.245, 'max_features': 6, 'min_impurity_decrease': 0.1, 'n_estimators': 100}\n",
            "0.972 (+/-0.028) for {'learning_rate': 0.245, 'max_features': 6, 'min_impurity_decrease': 0.1, 'n_estimators': 150}\n",
            "0.972 (+/-0.028) for {'learning_rate': 0.245, 'max_features': 6, 'min_impurity_decrease': 0.1, 'n_estimators': 200}\n",
            "0.958 (+/-0.068) for {'learning_rate': 0.245, 'max_features': 6, 'min_impurity_decrease': 0.01, 'n_estimators': 100}\n",
            "0.993 (+/-0.028) for {'learning_rate': 0.245, 'max_features': 6, 'min_impurity_decrease': 0.01, 'n_estimators': 150}\n",
            "0.979 (+/-0.034) for {'learning_rate': 0.245, 'max_features': 6, 'min_impurity_decrease': 0.01, 'n_estimators': 200}\n",
            "0.979 (+/-0.034) for {'learning_rate': 0.245, 'max_features': 6, 'min_impurity_decrease': 0.2, 'n_estimators': 100}\n",
            "0.979 (+/-0.034) for {'learning_rate': 0.245, 'max_features': 6, 'min_impurity_decrease': 0.2, 'n_estimators': 150}\n",
            "0.972 (+/-0.052) for {'learning_rate': 0.245, 'max_features': 6, 'min_impurity_decrease': 0.2, 'n_estimators': 200}\n",
            "0.986 (+/-0.034) for {'learning_rate': 0.245, 'max_features': 3, 'min_impurity_decrease': 0.1, 'n_estimators': 100}\n",
            "0.979 (+/-0.034) for {'learning_rate': 0.245, 'max_features': 3, 'min_impurity_decrease': 0.1, 'n_estimators': 150}\n",
            "0.986 (+/-0.034) for {'learning_rate': 0.245, 'max_features': 3, 'min_impurity_decrease': 0.1, 'n_estimators': 200}\n",
            "0.979 (+/-0.055) for {'learning_rate': 0.245, 'max_features': 3, 'min_impurity_decrease': 0.01, 'n_estimators': 100}\n",
            "0.986 (+/-0.034) for {'learning_rate': 0.245, 'max_features': 3, 'min_impurity_decrease': 0.01, 'n_estimators': 150}\n",
            "0.979 (+/-0.056) for {'learning_rate': 0.245, 'max_features': 3, 'min_impurity_decrease': 0.01, 'n_estimators': 200}\n",
            "0.979 (+/-0.034) for {'learning_rate': 0.245, 'max_features': 3, 'min_impurity_decrease': 0.2, 'n_estimators': 100}\n",
            "0.986 (+/-0.034) for {'learning_rate': 0.245, 'max_features': 3, 'min_impurity_decrease': 0.2, 'n_estimators': 150}\n",
            "0.965 (+/-0.044) for {'learning_rate': 0.245, 'max_features': 3, 'min_impurity_decrease': 0.2, 'n_estimators': 200}\n",
            "0.965 (+/-0.045) for {'learning_rate': 0.4, 'max_features': 6, 'min_impurity_decrease': 0.1, 'n_estimators': 100}\n",
            "0.972 (+/-0.053) for {'learning_rate': 0.4, 'max_features': 6, 'min_impurity_decrease': 0.1, 'n_estimators': 150}\n",
            "0.986 (+/-0.034) for {'learning_rate': 0.4, 'max_features': 6, 'min_impurity_decrease': 0.1, 'n_estimators': 200}\n",
            "0.979 (+/-0.035) for {'learning_rate': 0.4, 'max_features': 6, 'min_impurity_decrease': 0.01, 'n_estimators': 100}\n",
            "0.972 (+/-0.028) for {'learning_rate': 0.4, 'max_features': 6, 'min_impurity_decrease': 0.01, 'n_estimators': 150}\n",
            "0.979 (+/-0.034) for {'learning_rate': 0.4, 'max_features': 6, 'min_impurity_decrease': 0.01, 'n_estimators': 200}\n",
            "0.972 (+/-0.028) for {'learning_rate': 0.4, 'max_features': 6, 'min_impurity_decrease': 0.2, 'n_estimators': 100}\n",
            "0.972 (+/-0.052) for {'learning_rate': 0.4, 'max_features': 6, 'min_impurity_decrease': 0.2, 'n_estimators': 150}\n",
            "0.972 (+/-0.028) for {'learning_rate': 0.4, 'max_features': 6, 'min_impurity_decrease': 0.2, 'n_estimators': 200}\n",
            "0.965 (+/-0.044) for {'learning_rate': 0.4, 'max_features': 3, 'min_impurity_decrease': 0.1, 'n_estimators': 100}\n",
            "0.979 (+/-0.055) for {'learning_rate': 0.4, 'max_features': 3, 'min_impurity_decrease': 0.1, 'n_estimators': 150}\n",
            "0.965 (+/-0.044) for {'learning_rate': 0.4, 'max_features': 3, 'min_impurity_decrease': 0.1, 'n_estimators': 200}\n",
            "0.979 (+/-0.034) for {'learning_rate': 0.4, 'max_features': 3, 'min_impurity_decrease': 0.01, 'n_estimators': 100}\n",
            "0.972 (+/-0.052) for {'learning_rate': 0.4, 'max_features': 3, 'min_impurity_decrease': 0.01, 'n_estimators': 150}\n",
            "0.979 (+/-0.034) for {'learning_rate': 0.4, 'max_features': 3, 'min_impurity_decrease': 0.01, 'n_estimators': 200}\n",
            "0.965 (+/-0.076) for {'learning_rate': 0.4, 'max_features': 3, 'min_impurity_decrease': 0.2, 'n_estimators': 100}\n",
            "0.993 (+/-0.028) for {'learning_rate': 0.4, 'max_features': 3, 'min_impurity_decrease': 0.2, 'n_estimators': 150}\n",
            "0.979 (+/-0.055) for {'learning_rate': 0.4, 'max_features': 3, 'min_impurity_decrease': 0.2, 'n_estimators': 200}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       1.00      1.00      1.00        14\n",
            "          2       1.00      0.94      0.97        16\n",
            "          3       0.86      1.00      0.92         6\n",
            "\n",
            "avg / total       0.98      0.97      0.97        36\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[14  0  0]\n",
            " [ 0 15  1]\n",
            " [ 0  0  6]]\n",
            "Accuracy Score: \n",
            "\n",
            "0.9722222222222222\n",
            "---------------------------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qSYBCD4Lu3-6",
        "colab_type": "code",
        "outputId": "ff58a4e9-b683-4acc-802e-fbe2eb7bd538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1615
        }
      },
      "cell_type": "code",
      "source": [
        "#For XGBoost\n",
        "i=9\n",
        "EstimatorClass(scores[0],tuned_parameters[i],Clfier_array[i],PrintClfier_array[i])\n",
        "i+=1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for accuracy \n",
            "\n",
            "\n",
            "USING THE XGBClassifier ESTIMATOR\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'booster': 'gbtree', 'learning_rate': 0.245, 'min_child_weight': 3, 'nthread': -1}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.965 (+/-0.044) for {'booster': 'gbtree', 'learning_rate': 0.1, 'min_child_weight': 3, 'nthread': -1}\n",
            "0.965 (+/-0.044) for {'booster': 'gbtree', 'learning_rate': 0.1, 'min_child_weight': 3, 'nthread': 10}\n",
            "0.965 (+/-0.044) for {'booster': 'gbtree', 'learning_rate': 0.1, 'min_child_weight': 3, 'nthread': 100}\n",
            "0.958 (+/-0.052) for {'booster': 'gbtree', 'learning_rate': 0.1, 'min_child_weight': 5, 'nthread': -1}\n",
            "0.958 (+/-0.052) for {'booster': 'gbtree', 'learning_rate': 0.1, 'min_child_weight': 5, 'nthread': 10}\n",
            "0.958 (+/-0.052) for {'booster': 'gbtree', 'learning_rate': 0.1, 'min_child_weight': 5, 'nthread': 100}\n",
            "0.958 (+/-0.052) for {'booster': 'gbtree', 'learning_rate': 0.1, 'min_child_weight': 9, 'nthread': -1}\n",
            "0.958 (+/-0.052) for {'booster': 'gbtree', 'learning_rate': 0.1, 'min_child_weight': 9, 'nthread': 10}\n",
            "0.958 (+/-0.052) for {'booster': 'gbtree', 'learning_rate': 0.1, 'min_child_weight': 9, 'nthread': 100}\n",
            "0.972 (+/-0.028) for {'booster': 'gbtree', 'learning_rate': 0.245, 'min_child_weight': 3, 'nthread': -1}\n",
            "0.972 (+/-0.028) for {'booster': 'gbtree', 'learning_rate': 0.245, 'min_child_weight': 3, 'nthread': 10}\n",
            "0.972 (+/-0.028) for {'booster': 'gbtree', 'learning_rate': 0.245, 'min_child_weight': 3, 'nthread': 100}\n",
            "0.951 (+/-0.034) for {'booster': 'gbtree', 'learning_rate': 0.245, 'min_child_weight': 5, 'nthread': -1}\n",
            "0.951 (+/-0.034) for {'booster': 'gbtree', 'learning_rate': 0.245, 'min_child_weight': 5, 'nthread': 10}\n",
            "0.951 (+/-0.034) for {'booster': 'gbtree', 'learning_rate': 0.245, 'min_child_weight': 5, 'nthread': 100}\n",
            "0.965 (+/-0.063) for {'booster': 'gbtree', 'learning_rate': 0.245, 'min_child_weight': 9, 'nthread': -1}\n",
            "0.965 (+/-0.063) for {'booster': 'gbtree', 'learning_rate': 0.245, 'min_child_weight': 9, 'nthread': 10}\n",
            "0.965 (+/-0.063) for {'booster': 'gbtree', 'learning_rate': 0.245, 'min_child_weight': 9, 'nthread': 100}\n",
            "0.972 (+/-0.052) for {'booster': 'gbtree', 'learning_rate': 0.4, 'min_child_weight': 3, 'nthread': -1}\n",
            "0.972 (+/-0.052) for {'booster': 'gbtree', 'learning_rate': 0.4, 'min_child_weight': 3, 'nthread': 10}\n",
            "0.972 (+/-0.052) for {'booster': 'gbtree', 'learning_rate': 0.4, 'min_child_weight': 3, 'nthread': 100}\n",
            "0.958 (+/-0.068) for {'booster': 'gbtree', 'learning_rate': 0.4, 'min_child_weight': 5, 'nthread': -1}\n",
            "0.958 (+/-0.068) for {'booster': 'gbtree', 'learning_rate': 0.4, 'min_child_weight': 5, 'nthread': 10}\n",
            "0.958 (+/-0.068) for {'booster': 'gbtree', 'learning_rate': 0.4, 'min_child_weight': 5, 'nthread': 100}\n",
            "0.972 (+/-0.028) for {'booster': 'gbtree', 'learning_rate': 0.4, 'min_child_weight': 9, 'nthread': -1}\n",
            "0.972 (+/-0.028) for {'booster': 'gbtree', 'learning_rate': 0.4, 'min_child_weight': 9, 'nthread': 10}\n",
            "0.972 (+/-0.028) for {'booster': 'gbtree', 'learning_rate': 0.4, 'min_child_weight': 9, 'nthread': 100}\n",
            "0.965 (+/-0.044) for {'booster': 'dart', 'learning_rate': 0.1, 'min_child_weight': 3, 'nthread': -1}\n",
            "0.965 (+/-0.044) for {'booster': 'dart', 'learning_rate': 0.1, 'min_child_weight': 3, 'nthread': 10}\n",
            "0.965 (+/-0.044) for {'booster': 'dart', 'learning_rate': 0.1, 'min_child_weight': 3, 'nthread': 100}\n",
            "0.958 (+/-0.052) for {'booster': 'dart', 'learning_rate': 0.1, 'min_child_weight': 5, 'nthread': -1}\n",
            "0.958 (+/-0.052) for {'booster': 'dart', 'learning_rate': 0.1, 'min_child_weight': 5, 'nthread': 10}\n",
            "0.958 (+/-0.052) for {'booster': 'dart', 'learning_rate': 0.1, 'min_child_weight': 5, 'nthread': 100}\n",
            "0.958 (+/-0.052) for {'booster': 'dart', 'learning_rate': 0.1, 'min_child_weight': 9, 'nthread': -1}\n",
            "0.958 (+/-0.052) for {'booster': 'dart', 'learning_rate': 0.1, 'min_child_weight': 9, 'nthread': 10}\n",
            "0.958 (+/-0.052) for {'booster': 'dart', 'learning_rate': 0.1, 'min_child_weight': 9, 'nthread': 100}\n",
            "0.972 (+/-0.028) for {'booster': 'dart', 'learning_rate': 0.245, 'min_child_weight': 3, 'nthread': -1}\n",
            "0.972 (+/-0.028) for {'booster': 'dart', 'learning_rate': 0.245, 'min_child_weight': 3, 'nthread': 10}\n",
            "0.972 (+/-0.028) for {'booster': 'dart', 'learning_rate': 0.245, 'min_child_weight': 3, 'nthread': 100}\n",
            "0.951 (+/-0.034) for {'booster': 'dart', 'learning_rate': 0.245, 'min_child_weight': 5, 'nthread': -1}\n",
            "0.951 (+/-0.034) for {'booster': 'dart', 'learning_rate': 0.245, 'min_child_weight': 5, 'nthread': 10}\n",
            "0.951 (+/-0.034) for {'booster': 'dart', 'learning_rate': 0.245, 'min_child_weight': 5, 'nthread': 100}\n",
            "0.965 (+/-0.063) for {'booster': 'dart', 'learning_rate': 0.245, 'min_child_weight': 9, 'nthread': -1}\n",
            "0.965 (+/-0.063) for {'booster': 'dart', 'learning_rate': 0.245, 'min_child_weight': 9, 'nthread': 10}\n",
            "0.965 (+/-0.063) for {'booster': 'dart', 'learning_rate': 0.245, 'min_child_weight': 9, 'nthread': 100}\n",
            "0.972 (+/-0.052) for {'booster': 'dart', 'learning_rate': 0.4, 'min_child_weight': 3, 'nthread': -1}\n",
            "0.972 (+/-0.052) for {'booster': 'dart', 'learning_rate': 0.4, 'min_child_weight': 3, 'nthread': 10}\n",
            "0.972 (+/-0.052) for {'booster': 'dart', 'learning_rate': 0.4, 'min_child_weight': 3, 'nthread': 100}\n",
            "0.958 (+/-0.068) for {'booster': 'dart', 'learning_rate': 0.4, 'min_child_weight': 5, 'nthread': -1}\n",
            "0.958 (+/-0.068) for {'booster': 'dart', 'learning_rate': 0.4, 'min_child_weight': 5, 'nthread': 10}\n",
            "0.958 (+/-0.068) for {'booster': 'dart', 'learning_rate': 0.4, 'min_child_weight': 5, 'nthread': 100}\n",
            "0.972 (+/-0.028) for {'booster': 'dart', 'learning_rate': 0.4, 'min_child_weight': 9, 'nthread': -1}\n",
            "0.972 (+/-0.028) for {'booster': 'dart', 'learning_rate': 0.4, 'min_child_weight': 9, 'nthread': 10}\n",
            "0.972 (+/-0.028) for {'booster': 'dart', 'learning_rate': 0.4, 'min_child_weight': 9, 'nthread': 100}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.93      1.00      0.97        14\n",
            "          2       1.00      0.88      0.93        16\n",
            "          3       0.86      1.00      0.92         6\n",
            "\n",
            "avg / total       0.95      0.94      0.94        36\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[14  0  0]\n",
            " [ 1 14  1]\n",
            " [ 0  0  6]]\n",
            "Accuracy Score: \n",
            "\n",
            "0.9444444444444444\n",
            "---------------------------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "selBVSgSu3t3",
        "colab_type": "code",
        "outputId": "c6470818-e256-4636-8790-8041c9dc0fd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        }
      },
      "cell_type": "code",
      "source": [
        "# For NB\n",
        "\n",
        "i=10\n",
        "EstimatorClass(scores[0],tuned_parameters[i],Clfier_array[i],PrintClfier_array[i])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for accuracy \n",
            "\n",
            "\n",
            "USING THE GaussianNB ESTIMATOR\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'priors': None}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.972 (+/-0.053) for {'priors': None}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.88      1.00      0.93        14\n",
            "          2       1.00      0.81      0.90        16\n",
            "          3       0.86      1.00      0.92         6\n",
            "\n",
            "avg / total       0.93      0.92      0.92        36\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[14  0  0]\n",
            " [ 2 13  1]\n",
            " [ 0  0  6]]\n",
            "Accuracy Score: \n",
            "\n",
            "0.9166666666666666\n",
            "---------------------------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}